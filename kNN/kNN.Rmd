---
title: "**k-Nearest Neighbors algorithm (k-NN)**"
author: Xavier Vivancos García
date: '`r Sys.Date()`'
output: 
  html_document:
    number_sections: yes
    theme: cosmo
    highlight: tango
---

# Preparación

Leemos los datos, los normalizamos y los separamos en conjuntos de entrenamiento (70%) y test (30%).

```{r}
# Load library
library(class)

# Read data
data <- iris

# Normalization of all columns except Species
data[, -5] <- scale(iris[, -5])

# Reproducible results
set.seed(1234)

# 70% train and 30% test
ind <- sample(2, nrow(data), replace=TRUE, prob=c(0.7, 0.3))
trainData <- data[ind==1,]
testData <- data[ind==2,]
```

## Ejecución 

Ejecutamos el algoritmo con los siguientes parámetros:

* `train`. Matriz o _data frame_ con los datos de entrenamiento.

* `test`. Matriz o _data frame_ con los datos de test. Estos son los datos que el algoritmo tiene que clasificar.

* `cl`. Etiquetas de los datos de entrenamiento.

* `k`. Número de vecinos a considerar.

```{r}
# Execution of k-NN with k=1
KnnTestPrediction_k1 <- knn(trainData[, -5], testData[, -5],
                            trainData$Species, k=1, prob=TRUE)

# Execution of k-NN with k=2
KnnTestPrediction_k2 <- knn(trainData[, -5], testData[, -5],
                            trainData$Species, k=2, prob=TRUE)

# Execution of k-NN with k=3
KnnTestPrediction_k3 <- knn(trainData[, -5], testData[, -5],
                            trainData$Species, k=3, prob=TRUE)
```

## Evaluación

Evaluamos la precisión del algoritmo mediante matrices de confusión.

```{r}
# Confusion matrix of KnnTestPrediction_k1
table(testData$Species, KnnTestPrediction_k1)
```

¿Cómo interpretamos esta tabla?

* Las 10 observaciones pertenecientes a setosa han sido clasificadas correctamente como setosa.

* Las 12 observaciones pertenecientes a versicolor han sido clasificadas correctamente como versicolor.

* 2 observaciones pertenecientes a virginica han sido clasificadas erróneamente como versicolor.

El _accuracy_ es el siguiente:

```{r}
# Classification accuracy of KnnTestPrediction_k1
sum(KnnTestPrediction_k1==testData$Species)/length(testData$Species)*100
```

Para los otros valores de _k_:

```{r}
# Confusion matrix of KnnTestPrediction_k2
table(testData$Species, KnnTestPrediction_k2)

# Classification accuracy of KnnTestPrediction_k2
sum(KnnTestPrediction_k2==testData$Species)/length(testData$Species)*100

# Confusion matrix of KnnTestPrediction_k3
table(testData$Species, KnnTestPrediction_k3)

# Classification accuracy of KnnTestPrediction_k3
sum(KnnTestPrediction_k3==testData$Species)/length(testData$Species)*100
```

## Elección de _k_

¿Cuál es el valor óptimo de _k_?

```{r fig.align='center'}
# Empty variables
KnnTestPrediction <- list()
accuracy <- numeric()

# From k=1 to k=100...
for(k in 1:100){

  # KnnTestPrediction for each k
  KnnTestPrediction[[k]] <- knn(trainData[,-5], testData[,-5], trainData$Species, k, prob=TRUE)
    
  # Accuracy for each k   
  accuracy[k] <- sum(KnnTestPrediction[[k]]==testData$Species)/length(testData$Species)*100

}

# Accuracy vs Choice of k
plot(accuracy, type="b", col="dodgerblue", cex=1, pch=20,
     xlab="k, number of neighbors", ylab="% Classification accuracy", 
     main="Accuracy vs Neighbors")

# Add lines indicating k with best accuracy
abline(v=which(accuracy==max(accuracy)), col="darkorange", lwd=1.5)

# Add line for max accuracy seen
abline(h=max(accuracy), col="grey", lty=2)

# Add line for min accuracy seen 
abline(h=min(accuracy), col="grey", lty=2)
```
